# Team-Info
| (1) 과제명 | *스마트푸푸:시각장애인 양육자 대상, YOLO와 Multimodal LLM을 활용한, 아기변 분류 기반, 건강 상태 모니터링 서비스*
|:-----------  |---  |
| (2) 팀 번호 / 팀 이름 | *17-포카리* |
| (3) 팀 구성원 | 박기선 (1876137): 리더, *FE* <br> 김수연 (2076061): 팀원, *AI, BE* <br> 이은서 (2076320) : 팀원, *BE*            |
| (4) 팀 지도교수 | 민동보 교수님 |
| (5) 팀 멘토 | 문효진 / 개발자 / 네이버 |
| (6) 과제 분류 | *산학과제* |
| (6) 과제 키워드 | *Object Detection, Multimodal LLM, Computer Vision, STT, TTS, HCI, Accessibility*  |
| (7) 과제 내용 요약 | *시각장애인이 양육을 할 때 불편을 겪는 문제에는 임신 테스트기를 확인하는 것부터 기저귀 속 변의 색상이나 형태를 확인하여 아기의 건강상태를 확인하는 것까지 다양하다. 스마트푸푸는 시각장애인의 활동지원인이나 가족들의 부재에도 이러한 문제 해결을 지원하는 서비스이다.* |


<br>

<br>

# Project-Summary
| 항목 | 내용|
|:----------  |---  |
| **(1) 문제 정의**   | **1. 시각장애인 양육자들은 필수 양육 행동인 아기 변 상태 확인이 어렵고, 그나마도 직접 만져 질감만 확인하고 있다.**<br>   - 용변은 사람의 건강 상태를 빠르게 짐작할 수 있는 바로미터이다. 더구나 아기는 의사표현을 말로 할 수 없기에 기저귀를 체크하는 것은 필수 양육 행동이다. 변의 색상이 이상하면 병원 진료를 받거나, 설사를 하면 탈수를 유의하는 등 후속조치가 뒤따라야 하기 때문이다. 그러나 시각장애 양육자들에 따르면 그들은 아기의 변을 항상 직접 만져보고 있다. 아기는 하루에 최대 10번까지 용변을 보기도 하는데, 그 때마다 가족이나 활동지원인에게 도움을 청하는 것은 무리가 있다. 게다가 용변이라는 특수성 때문에 더욱 요청이 어렵다.<br><br> **2. 임신 여부도 확인하기 어렵다.**<br>   - 시중에 판매되고 있는 임신테스터기는 시각적으로만 결과를 확인할 수 있다. 확인해줄 주변인, 혹은 의사의 진료없이는 시각장애인이 스스로 본인의 임신상태를 파악할 수 있는 방법이 없다.<br><br> **3. 기존 서비스는 한국어를 모국어로 하는 시각장애인의 사용성을 고려하지 않았다.**<br>   - 다음 항목에서 확인할 수 있는 기존 서비스들은 접근성이나 언어의 장벽 측면에서 사용이 어렵다. |
| **(2) 기존연구와의 비교** | **1. StoolNet (성인 변 이미지 분류 모델)**<br>   - 장점: 변을 건강에 대한 주요 지표로 연구했다.<br>   - 단점: 성인변에만 한정되었고 특수 변기를 사용한 이미지만 고려했으며 복합적인 상태에 대해서 기술하지 못한다. 상용화되지 않아 연구 자료나 결과를 활용할 수 없으며 시각장애인의 접근성 또한 고려되지 않았다.<br><br> **2. 매일 아기똥 솔루션**<br>   - 장점: 전문의의 소견을 들을 수 있다.<br>   - 단점: 오전 6시부터 선착순 100명에게만 답변을 제공한다. 결과를 얻는 데까지 최대 24시간이 소요되며, 주말에는 서비스를 이용할 수 없다. 시각장애인 양육자가 사용하기에 접근성이 좋지 않다. 추가적인 질문을 할 수 없다. <br><br> **3. Be My Eyes**<br>   - 장점: 자원봉사자와의 실시간 매칭을 통해 시각장애인이 임신 여부를 확인할 수 있다.<br>   - 단점: 글로벌 서비스이므로 외국인 자원봉사자와의 대화를 위해 영어 구사가 가능해야 한다. 다른 사람에게 의존해야 한다. <br><br> **본 서비스의 강점**<br> - 기존서비스들과 달리 스마트푸푸는 사용자가 시간과 장소에 구애받지 않으며 타인에게 의존하지 않고도 아기 변 상태를 직접 모니터링할 수 있는 서비스를 제공한다.  다양한 상태의 변에 대해 복합적으로 고려할 수 있으며, 병원 내원을 하기 전 추가 질문이 있을 경우 챗봇을 통해 간단히 해결할 수 있다. 또한 사용자 스스로 본인의 임신 상태를 확인할 수 있다. |
| **(3) 제안 내용**   | 1. (시각장애인 양육자가 아기의 변을 통해 건강 상태를 확인할 수 있도록 돕는 기술이 필요하다)<br> **→ 기저귀 이미지 속 똥을 토대로 건강 상태를 조언하고 대책을 제안하는 서비스를 제공하며, 챗봇을 통해 관련된 내용에 대한 질문을 주고 받을 수 있다.** <br><br> 2. (시각장애인 여성이 스스로 본인의 임신여부를 확인할 수 있도록 돕는 기술이 필요하다)<br>  **→ 임신테스트기를 탐지하여 이미지 분류를 통해 임신/비임신 여부 알려주는 서비스 제공**<br><br> 3. (시각장애인의 사용성을 고려해야 한다)<br>  → **기저귀를 탐지하여 자동으로 촬영하는 카메라 기능 제공, STT/TTS, VoiceOver/TalkBack, 간단한 UI/UX 구성**<br>  |
| **(4) 기대효과 및 의의** | 1. 시간과 장소에 구애받지 않고 아이의 변 상태 확인이 가능해 양육장벽을 해소할 수 있다.<br> 2. 양육자가 직접 아이의 건강 상태를 모니터링 및 관리함으로써 모·부성권을 보호할 수 있다.<br> 3. 장애인 양육자에게 주어지는 유일한 지원이 일회성 출산 장려금 뿐이며, 장애별 특성을 고려한 육아 지원은 전무한 상황에서 시각장애인 부모 맞춤형 서비스를 제공함으로써 복지 사각지대를 해소한다. |
| **(5) 주요 기능 리스트** | **1. 사용성을 고려한 UX/UI**<br>1) 간단한 화면 구성 - 적은 움직임으로도 편하게 사용할 수 있도록 구성했다. <br>2) 모든 화면에서 TTS/STT 및 voiceover/talkback을 통한 조작 지원 - 음성 서비스를 통해 시각장애인 사용자의 편의성을 높인다.<br>3) 실시간 기저귀 탐지 앱 내 카메라 - 기저귀 촬영을 원활하게 할 수 있도록 돕는다.<br>4) 핵심 기능 외 불필요한 절차 생략 - 널리 사용되는 시각장애인 대상 어플들을 분석해보면 가입이나 로그인 등의 잡다한 절차를 거치지 않고, 로딩과 동시에 바로 사용할 수 있도록 제작되어 있었다. 마찬가지로 철저히 시각장애 사용자의 편의에 집중하고자 로그인 절차를 생략했다.<br><br> **2. 아기 변 상태 분석 및 챗봇 문답 기능**<br>   -  타인의 도움없이 아기 변 상태를 확인하고 관련한 궁금증을 해결할 수 있다.<br><br> **3. 임신테스트기 결과 분석 기능**<br>   - 진동 및 소리로 전달되는 결과를 통해 스스로 임신 상태를 확인할 수 있다. |

<br>

# Project-Design
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **클래스다이어그램**<br><img src="https://github.com/user-attachments/assets/266f6944-afc8-49a1-a7a6-f1a7f71d3da7" alt="image" width="700"/><br>**시스템플로우차트**<br><img src="https://github.com/user-attachments/assets/4808f286-74b9-456c-837f-97ed79eb77d8" alt="image" width="700"/><br>**솔루션구조**<br><img width="700" alt="image" src="https://github.com/user-attachments/assets/5b807bea-8e80-4c23-8f72-75df2ca03d77">|
| (2) 전체 시스템 구성 | <img width="700" alt="image" src="https://github.com/user-attachments/assets/30aab794-c413-4c3c-b4c6-16112f7d5305"><br>**실시간 객체 탐지 카메라 모듈**<br>1) 객체 감지 및 이미지 프레임 분석<br> - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 분석<br>2) 모델 로딩<br>- 직접 훈련시킨 기저귀 TFlite 파일을 불러옴<br>3) 기저귀 객체 탐지<br> - YOLOV5 커스텀 모델<br>  - 이미지 수집  : 설문조사 및 인터넷 크롤링, 직접 촬영을 통해  다양한 상태의 아기 기저귀 변 이미지 97개 수집함<br>   - 이미지 전처리 : 정확한 판단을 위해 AutoWhiteBalancing 으로 흰 부분의 흰색으로 보이도록 색보정<br>   - 이미지 라벨링 : Roboflow 를 사용하여 기저귀 bounding box 지정 및 라벨링<br>   - 기저귀에 대한 단일 라벨 지정<br>   - 이미지 증강 :  랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강  - 233개<br>4) 결과 출력 및 시각화<br><br>**아기 변 분석 및 챗봇 모듈**<br>1) OPEN AI API 요청<br>   - 프롬프팅 : "아기 기저귀 사진의 똥 부분만 보고 건강 상태를 설명해줘. 이상이 있다면 가능한 원인과 추가로 확인해야 할 사항에 대해 알려줘. 똥이 없는 경우는 000 이라고만 해"<br>   - 변 이미지와 프롬프트를 OPEN AI ChatGPT-4o 모델에 입력으로 전달<br>   - 식별 가능한 아기 변이 있는 기저귀 이미지라면 건강 분석 결과를,  아니라면 촬영 재요청을 위한 “000” 반환<br>   - 챗봇 사용 시 이전 대화 기록이 필요하므로 conversation_history 리스트에 입력 및 답변 순차적으로 저장<br>2) 챗봇<br>   - 음성 인식을 통해 사용자로부터 추가 질문 입력 받음 →  종료시까지 추가질문 프로세스 반복<br>  - 메시지 처리  - conversation_history 와 입력 받은 추가질문을 ChatGPT-4o 모델에 입력으로 전달<br>   - 답변을 사용자에게 전달하고 converstation_history에 추가질문과 답변 저장<br><br>**임신테스트기 분류 모듈**<br>1) 객체 감지 및 이미지 처리<br> - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 처리<br>2) 모델 로딩<br >- Roboflow로 학습시킨 모델을 API를 통해 가져옴<br>3) 임신테스트기 이미지 분류<br> - Roboflow 를 활용한 OPEN AI ChatGPT-4o fine-tuning 커스텀 모델<br>   - 이미지 수집 : 인터넷 크롤링을 통해 임신/비임신 테스트기 결과 이미지 62개 수집함<br>   - 이미지 라벨링 : Roboflow 를 사용하여 결과 부분 bounding box 지정 및 라벨링<br>    - 임신/비임신 2개의 라벨 - 0,1<br>   - 이미지 증강 : 랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강 - 150개<br>  - 모델 훈련 : 코로나19 테스트기 이미지 추가 활용 예정  |
| (3) 진척도 및 검증내역 | **1) 검증내역**<br>- StoolNet, CNN, YOLOv5 등의 모델을 사용하여 이미지 분류 성능을 검증하였고, ChatGPT-4o가 변 분석과 포괄성에서 우수한 성능을 보임을 확인하여 진단 모델로 결정했다.<br>    - 라벨이 존재하는 데이터가 아니었기 때문에 정확한 정량적 비교가 불가능하나 중간발표에서 각각의 결과를 통해 검증 결과를 보였다. <br>- YOLOv5를 사용하는 기저귀 객체 탐지 모델을 검증하기 위해 이미지를 수집,라벨링, 전처리 후 훈련하여 정확도 0.991, 평균정밀도 0.995의 결과를 얻었다. <br>- ChatGPT4o를 다양한 프롬프팅을 통해 파인튜닝했다.<br>- 진단 모델 및 테스터기 모델, 챗봇 사용을 위한 각각의 API를 구현했다.<br>- 프론트에서 실시간 객체 탐지가 가능하도록 구현했다.<br>- 이미지 전처리 알고리즘을 구현했다. <br>- STT/TTS 및 talkback/voiceover 구동을 확인했다.<br>**2) 진척도**<br>- 약 70% 정도 <br>- 중간 발표 후 기능 추가를 고려하면 좋겠다는 피드백을 반영하여 임신 테스트기 결과 확인 기능을 추가 구현하고 있고, 프론트와 백을 병합하는 과정에 있다. 또한 사용성을 고려하여 UI/UX를 개선 중에 있다.|
| (4) 기타 |  |


<br>


