# Team-Info
| (1) 과제명 | *스마트푸푸:시각장애인 양육자 대상, YOLO와 Multimodal LLM을 활용한, 아기변 분류 기반, 건강 상태 모니터링 서비스*
|:-----------  |---  |
| (2) 팀 번호 / 팀 이름 | *17-포카리* |
| (3) 팀 구성원 | 박기선 (1876137): 리더, *FE* <br> 김수연 (2076061): 팀원, *AI* |
| (4) 팀 지도교수 | 민동보 교수님 |
| (5) 팀 멘토 | 문효진 / 개발자 / 네이버 |
| (6) 과제 분류 | *산학과제* |
| (6) 과제 키워드 | *Object Detection, Multimodal LLM, Computer Vision, STT, TTS, HCI, Accessibility*  |
| (7) 과제 내용 요약 | *시각장애인이 양육을 할 때 불편을 겪는 문제에는 임신 테스트기를 확인하는 것부터 기저귀 속 변의 색상이나 형태를 확인하여 아기의 건강상태를 확인하는 것까지 다양하다. 스마트푸푸는 시각장애인의 활동지원인이나 가족들의 존재 여부와 상관 없이 이러한 문제 해결을 지원하는 서비스이다.* |


<br>

<br>

# Project-Summary
| 항목 | 내용|
|:----------  |---  |
| **(1) 문제 정의**   | **1. 시각장애인 양육자들은 필수 양육 행동인 아기 변 상태 확인이 어렵고, 그나마도 직접 만져 질감만 확인하고 있다.**<br>   - 용변은 사람의 건강 상태를 빠르게 짐작할 수 있는 바로미터이다. 더구나 아기는 의사표현을 말로 할 수 없기에 기저귀를 체크하는 것은 필수 양육 행동이다. 변의 색상이 이상하면 병원 진료를 받거나, 설사를 하면 탈수를 유의하는 등 후속조치가 뒤따라야 하기 때문이다. 그러나 시각장애 양육자들에 따르면 그들은 아기의 변을 항상 직접 만져보고 있다. 아기는 하루에 최대 10번까지 용변을 보기도 하는데, 그 때마다 가족이나 활동지원인에게 도움을 청하는 것은 무리가 있다. 게다가 용변이라는 특수성 때문에 더욱 요청이 어렵다.<br><br> **2. 임신 여부도 확인하기 어렵다.**<br>   - 시중에 판매되고 있는 임신테스터기는 시각적으로만 결과를 확인할 수 있다. 확인해줄 주변인, 혹은 의사의 진료없이는 시각장애인이 스스로 본인의 임신상태를 파악할 수 있는 방법이 없다.<br><br> **3. 기존 서비스는 한국어를 모국어로 하는 시각장애인의 사용성을 고려하지 않았다.**<br>   - 다음 항목에서 확인할 수 있는 기존 서비스들은 접근성이나 언어의 장벽 측면에서 사용이 어렵다. |
| **(2) 기존연구와의 비교** | **1. StoolNet (성인 변 이미지 분류 모델)**<br>   - 장점: 변을 건강에 대한 주요 지표로 연구했다.<br>   - 단점: 성인변에만 한정되었고 특수 변기를 사용한 이미지만 고려했으며 복합적인 상태에 대해서 기술하지 못한다. 상용화되지 않아 연구 자료나 결과를 활용할 수 없으며 시각장애인의 접근성 또한 고려되지 않았다.<br><br> **2. 매일 아기똥 솔루션**<br>   - 장점: 전문의의 소견을 들을 수 있다.<br>   - 단점: 오전 6시부터 선착순 100명에게만 답변을 제공한다. 결과를 얻는 데까지 최대 24시간이 소요되며, 주말에는 서비스를 이용할 수 없다. 시각장애인 양육자가 사용하기에 접근성이 좋지 않다. 추가적인 질문을 할 수 없다. <br><br> **3. Be My Eyes**<br>   - 장점: 자원봉사자와의 실시간 매칭을 통해 시각장애인이 임신 여부를 확인할 수 있다.<br>   - 단점: 글로벌 서비스이므로 외국인 자원봉사자와의 대화를 위해 영어 구사가 가능해야 한다. 다른 사람에게 의존해야 한다. <br><br> **본 서비스의 강점**<br> - 기존서비스들과 달리 스마트푸푸는 사용자가 시간과 장소에 구애받지 않으며 타인에게 의존하지 않고도 아기 변 상태를 직접 모니터링할 수 있는 서비스를 제공한다.  다양한 상태의 변에 대해 복합적으로 고려할 수 있으며, 병원 내원을 하기 전 추가 질문이 있을 경우 챗봇을 통해 간단히 해결할 수 있다. 또한 사용자 스스로 본인의 임신 상태를 확인할 수 있다. |
| **(3) 제안 내용**   | <ins> 스마트푸푸는 아래와 같이 시각장애인 양육자가 직접 아기 변 상태를 모니터링하고 시각장애인 여성 스스로 임신 테스트기 결과를 확인할 수 있도록 돕는 서비스이다. </ins><br><br>1. (시각장애인 양육자가 아기의 변을 통해 건강 상태를 확인할 수 있도록 돕는 기술이 필요하다)<br> **→ 기저귀 이미지 속 똥을 토대로 건강 상태를 조언하고 대책을 제안하는 서비스를 제공하며, 챗봇을 통해 관련된 내용에 대한 질문을 주고 받을 수 있다.** <br><br> 2. (시각장애인 여성이 스스로 본인의 임신여부를 확인할 수 있도록 돕는 기술이 필요하다)<br>  **→ 임신테스트기를 탐지하여 이미지 분류를 통해 임신/비임신 여부 알려주는 서비스 제공**<br><br> 3. (시각장애인의 사용성을 고려해야 한다)<br>  → **기저귀를 탐지하여 자동으로 촬영하는 카메라 기능 제공, STT/TTS, VoiceOver/TalkBack, 간단한 UI/UX 구성**<br>  |
| **(4) 기대효과 및 의의** | 1. 시간과 장소에 구애받지 않고 아이의 변 상태 확인이 가능해 양육장벽을 해소할 수 있다.<br> 2. 양육자가 직접 아이의 건강 상태를 모니터링 및 관리함으로써 모·부성권을 보호할 수 있다.<br> 3. 장애인 양육자에게 주어지는 유일한 지원이 일회성 출산 장려금 뿐이며, 장애별 특성을 고려한 육아 지원은 전무한 상황에서 시각장애인 부모 맞춤형 서비스를 제공함으로써 복지 사각지대를 해소한다. |
| **(5) 주요 기능 리스트** | **1. 사용성을 고려한 UX/UI**<br>1) 간단한 화면 구성 - 적은 움직임으로도 편하게 사용할 수 있도록 구성했다. <br>2) 모든 화면에서 TTS/STT 및 voiceover/talkback을 통한 조작 지원 - 음성 서비스를 통해 시각장애인 사용자의 편의성을 높인다.<br>3) 실시간 기저귀 탐지 앱 내 카메라 - 기저귀 촬영을 원활하게 할 수 있도록 돕는다.<br>4) 핵심 기능 외 불필요한 절차 생략 - 널리 사용되는 시각장애인 대상 어플들을 분석해보면 가입이나 로그인 등의 잡다한 절차를 거치지 않고, 로딩과 동시에 바로 사용할 수 있도록 제작되어 있었다. 마찬가지로 철저히 시각장애 사용자의 편의에 집중하고자 로그인 절차를 생략했다.<br><br> **2. 아기 변 상태 분석 및 챗봇 문답 기능**<br>   -  타인의 도움없이 아기 변 상태를 확인하고 관련한 궁금증을 해결할 수 있다.<br><br> **3. 임신테스트기 결과 분석 기능**<br>   - 진동 및 소리로 전달되는 결과를 통해 스스로 임신 상태를 확인할 수 있다. |

<br>

# Project-Design
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **기능별 요구사항 리스트**<br><img src="https://github.com/user-attachments/assets/87394541-18b1-4d41-800c-baa3581774b0" alt="image" width="700"/><br>**솔루션구조**<br><img width="700" alt="image" src="https://github.com/user-attachments/assets/5b807bea-8e80-4c23-8f72-75df2ca03d77">|
| (2) 전체 시스템 구성 | <img width="700" alt="image" src="https://github.com/user-attachments/assets/2a8388c3-b47a-462c-a8fb-fe7e27dc65d0"> <br>**실시간 객체 탐지 카메라 모듈**<br>1) 객체 감지 및 이미지 프레임 분석<br> - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 분석<br>2) 모델 로딩<br>- 직접 훈련시킨 기저귀 TFlite 파일을 불러옴<br>3) 기저귀 객체 탐지<br> - YOLOV11 커스텀 모델<br>  - 이미지 수집  : 설문조사 및 인터넷 크롤링, 직접 촬영을 통해  다양한 상태의 아기 기저귀 변 이미지 97개 수집함<br>  - 이미지 전처리 : 정확한 판단을 위해 AutoWhiteBalancing 으로 흰 부분의 흰색으로 보이도록 색보정<br>  - 이미지 라벨링 : Roboflow 를 사용하여 기저귀 bounding box 지정 및 라벨링<br>  - 기저귀에 대한 단일 라벨 지정<br>  - 이미지 증강 :  랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강  - 233개<br>4) 결과 출력 및 시각화<br><br>**아기 변 분석 및 챗봇 모듈**<br>1) OPEN AI API 요청<br>  - 프롬프팅 : [아기 기저귀 사진의 똥 부분만 보고 건강 상태를 설명해줘. 이상이 있다면 가능한 원인과 추가로 확인해야 할 사항에 대해 알려줘. 똥이 없는 경우는 000 이라고만 해]<br>  - 변 이미지와 프롬프트를 OPEN AI ChatGPT-4o 모델에 입력으로 전달<br>  - 식별 가능한 아기 변이 있는 기저귀 이미지라면 건강 분석 결과를, 아니라면 촬영 재요청을 위한 “000” 반환<br>  - 챗봇 사용 시 이전 대화 기록이 필요하므로 conversation_history 리스트에 입력 및 답변 순차적으로 저장<br>2) 챗봇<br>  - 음성 인식을 통해 사용자로부터 추가 질문 입력 받음 →  종료시까지 추가질문 프로세스 반복<br>  - 메시지 처리  - conversation_history 와 입력 받은 추가질문을 ChatGPT-4o 모델에 입력으로 전달<br>  - 답변을 사용자에게 전달하고 converstation_history에 추가질문과 답변 저장<br><br>**임신테스트기 분류 모듈**<br>1) 객체 감지 및 이미지 처리<br>  - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 처리<br>2) 모델 로딩<br >- Roboflow로 학습시킨 모델을 API를 통해 가져옴<br>3) 임신테스트기 이미지 분류<br>  - Roboflow 를 활용한 OPEN AI ChatGPT-4o fine-tuning 커스텀 모델<br>  - 이미지 수집 : 인터넷 크롤링을 통해 임신/비임신 테스트기 결과 이미지 62개 수집함<br>  - 이미지 라벨링 : Roboflow 를 사용하여 결과 부분 bounding box 지정 및 라벨링<br>  - 임신/비임신 2개의 라벨 - 0,1<br>  - 이미지 증강 : 랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강 - 150개<br>  - 모델 훈련 : 코로나19 테스트기 이미지 추가 활용 예정 |
| (3) 주요 엔진 및 기능 설계 | **1) 객체탐지 및 촬영 모듈**<br>- Google ML Kit와 Custom YOLOv5 모델로 훈련된 TFlite 파일을 활용하여 이미지 내에서 기저귀를 감지하고, 필요한 영역만 추출한다. <br> **2) 아기 변 분석 모듈** <br> - 1에서 추출된 이미지를 ChatGPT 모델과 연동된 아기 변 분석 모듈이 분석한다. <br> **3) 챗봇 모듈**<br>- OpenAI의 ChatGPT API를 사용하여 변 상태 분석 결과와 연동하여 사용자 질문에 대한 답변을 생성한다. 이때 병원 방문을 권유하는 문장도 필요에 따라 답변에 포함된다. |
| (4) 주요 기능의 구현 | 사용자가 객체탐지 및 촬영 모듈을 통해 이미지를 촬영하면 기저귀와 변을 인식하여 변 상태 분석 모듈로 전달하고, 변 상태 분석 모듈은 이를 분석하여 변의 상태를 설명한다. 아기 변 상태에 대한 설명은 다시 챗봇 모듈로 전달되어 현재 상태와 관련된 추가 질문에 답변한다. 이후 사용자가 음성으로 추가 질문을 하면 STT로 질문 텍스트를 챗봇으로 보내고, 답변을 TTS로 전달하여 사용자가 답변 내용을 음성으로 들을 수 있다. |
| (5) 기타 | |


<br>

