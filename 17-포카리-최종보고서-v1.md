# Team-Info
| (1) 과제명 | *스마트푸푸:시각장애인 양육자 대상, YOLO와 Multimodal LLM을 활용한, 아기변 분류 기반, 건강 상태 모니터링 서비스*
|:-----------  |---  |
| (2) 팀 번호 / 팀 이름 | *17-포카리* |
| (3) 팀 구성원 | 박기선 (1876137): 리더, *FE* <br> 김수연 (2076061): 팀원, *AI* |
| (4) 팀 지도교수 | 민동보 교수님 |
| (5) 팀 멘토 | 문효진 / 개발자 / 네이버 |
| (6) 과제 분류 | *산학과제* |
| (6) 과제 키워드 | *Object Detection, Multimodal LLM, Computer Vision, STT, TTS, HCI, Accessibility*  |
| (7) 과제 내용 요약 | *시각장애인이 양육을 할 때 불편을 겪는 문제에는 임신 테스트기를 확인하는 것부터 기저귀 속 변의 색상이나 형태를 확인하여 아기의 건강상태를 확인하는 것까지 다양하다. 스마트푸푸는 시각장애인의 활동지원인이나 가족들의 존재 여부와 상관 없이 이러한 문제 해결을 지원하는 서비스이다.* |


<br>

<br>

# Project-Summary
| 항목 | 내용|
|:----------  |---  |
| **(1) 문제 정의**   | **1. 시각장애인 양육자들은 필수 양육 행동인 아기 변 상태 확인이 어렵고, 그나마도 직접 만져 질감만 확인하고 있다.**<br>   - 용변은 사람의 건강 상태를 빠르게 짐작할 수 있는 바로미터이다. 더구나 아기는 의사표현을 말로 할 수 없기에 기저귀를 체크하는 것은 필수 양육 행동이다. 변의 색상이 이상하면 병원 진료를 받거나, 설사를 하면 탈수를 유의하는 등 후속조치가 뒤따라야 하기 때문이다. 그러나 시각장애 양육자들에 따르면 그들은 아기의 변을 항상 직접 만져보고 있다. 아기는 하루에 최대 10번까지 용변을 보기도 하는데, 그 때마다 가족이나 활동지원인에게 도움을 청하는 것은 무리가 있다. 게다가 용변이라는 특수성 때문에 더욱 요청이 어렵다.<br><br> **2. 임신 여부도 확인하기 어렵다.**<br>   - 시중에 판매되고 있는 임신테스터기는 시각적으로만 결과를 확인할 수 있다. 확인해줄 주변인, 혹은 의사의 진료없이는 시각장애인이 스스로 본인의 임신상태를 파악할 수 있는 방법이 없다.<br><br> **3. 기존 서비스는 한국어를 모국어로 하는 시각장애인의 사용성을 고려하지 않았다.**<br>   - 다음 항목에서 확인할 수 있는 기존 서비스들은 접근성이나 언어의 장벽 측면에서 사용이 어렵다. |
| **(2) 기존연구와의 비교** | **1. StoolNet (성인 변 이미지 분류 모델)**<br>   - 장점: 변을 건강에 대한 주요 지표로 연구했다.<br>   - 단점: 성인변에만 한정되었고 특수 변기를 사용한 이미지만 고려했으며 복합적인 상태에 대해서 기술하지 못한다. 상용화되지 않아 연구 자료나 결과를 활용할 수 없으며 시각장애인의 접근성 또한 고려되지 않았다.<br><br> **2. 매일 아기똥 솔루션**<br>   - 장점: 전문의의 소견을 들을 수 있다.<br>   - 단점: 오전 6시부터 선착순 100명에게만 답변을 제공한다. 결과를 얻는 데까지 최대 24시간이 소요되며, 주말에는 서비스를 이용할 수 없다. 시각장애인 양육자가 사용하기에 접근성이 좋지 않다. 추가적인 질문을 할 수 없다. <br><br> **3. Be My Eyes**<br>   - 장점: 자원봉사자와의 실시간 매칭을 통해 시각장애인이 임신 여부를 확인할 수 있다.<br>   - 단점: 글로벌 서비스이므로 외국인 자원봉사자와의 대화를 위해 영어 구사가 가능해야 한다. 다른 사람에게 의존해야 한다. <br><br> **본 서비스의 강점**<br> - 기존서비스들과 달리 스마트푸푸는 사용자가 시간과 장소에 구애받지 않으며 타인에게 의존하지 않고도 아기 변 상태를 직접 모니터링할 수 있는 서비스를 제공한다.  다양한 상태의 변에 대해 복합적으로 고려할 수 있으며, 병원 내원을 하기 전 추가 질문이 있을 경우 챗봇을 통해 간단히 해결할 수 있다. 또한 사용자 스스로 본인의 임신 상태를 확인할 수 있다. |
| **(3) 제안 내용**   | <ins> 스마트푸푸는 아래와 같이 시각장애인 양육자가 직접 아기 변 상태를 모니터링하고 시각장애인 여성 스스로 임신 테스트기 결과를 확인할 수 있도록 돕는 서비스이다. </ins><br><br>1. (시각장애인 양육자가 아기의 변을 통해 건강 상태를 확인할 수 있도록 돕는 기술이 필요하다)<br> **→ 기저귀 이미지 속 똥을 토대로 건강 상태를 조언하고 대책을 제안하는 서비스를 제공하며, 챗봇을 통해 관련된 내용에 대한 질문을 주고 받을 수 있다.** <br><br> 2. (시각장애인 여성이 스스로 본인의 임신여부를 확인할 수 있도록 돕는 기술이 필요하다)<br>  **→ 임신테스트기를 탐지하여 이미지 분류를 통해 임신/비임신 여부 알려주는 서비스 제공**<br><br> 3. (시각장애인의 사용성을 고려해야 한다)<br>  → **기저귀를 탐지하여 자동으로 촬영하는 카메라 기능 제공, STT/TTS, VoiceOver/TalkBack, 간단한 UI/UX 구성**<br>  |
| **(4) 기대효과 및 의의** | 1. 시간과 장소에 구애받지 않고 아이의 변 상태 확인이 가능해 양육장벽을 해소할 수 있다.<br> 2. 양육자가 직접 아이의 건강 상태를 모니터링 및 관리함으로써 모·부성권을 보호할 수 있다.<br> 3. 장애인 양육자에게 주어지는 유일한 지원이 일회성 출산 장려금 뿐이며, 장애별 특성을 고려한 육아 지원은 전무한 상황에서 시각장애인 부모 맞춤형 서비스를 제공함으로써 복지 사각지대를 해소한다. |
| **(5) 주요 기능 리스트** | **1. 사용성을 고려한 UX/UI**<br>1) 간단한 화면 구성 - 적은 움직임으로도 편하게 사용할 수 있도록 구성했다. <br>2) 모든 화면에서 TTS/STT 및 voiceover/talkback을 통한 조작 지원 - 음성 서비스를 통해 시각장애인 사용자의 편의성을 높인다.<br>3) 실시간 기저귀 탐지 앱 내 카메라 - 기저귀 촬영을 원활하게 할 수 있도록 돕는다.<br>4) 핵심 기능 외 불필요한 절차 생략 - 널리 사용되는 시각장애인 대상 어플들을 분석해보면 가입이나 로그인 등의 잡다한 절차를 거치지 않고, 로딩과 동시에 바로 사용할 수 있도록 제작되어 있었다. 마찬가지로 철저히 시각장애 사용자의 편의에 집중하고자 로그인 절차를 생략했다.<br><br> **2. 아기 변 상태 분석 및 챗봇 문답 기능**<br>   -  타인의 도움없이 아기 변 상태를 확인하고 관련한 궁금증을 해결할 수 있다.<br><br> **3. 임신테스트기 결과 분석 기능**<br>   - 진동 및 소리로 전달되는 결과를 통해 스스로 임신 상태를 확인할 수 있다. |

<br>

# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **기능별 요구사항 리스트**<br><img src="https://github.com/user-attachments/assets/87394541-18b1-4d41-800c-baa3581774b0" alt="image" width="700"/><br>**솔루션구조**<br><img width="700" alt="image" src="https://github.com/user-attachments/assets/5b807bea-8e80-4c23-8f72-75df2ca03d77">|
| (2) 전체 시스템 구성 | <img width="700" alt="image" src="https://github.com/user-attachments/assets/c663c861-981b-4b17-9ab3-b3d740733365"><br>**실시간 객체 탐지 카메라 모듈**<br>1) 객체 감지 및 이미지 프레임 분석<br> - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 분석<br>2) 모델 로딩<br>- 직접 훈련시킨 기저귀 TFlite 파일을 불러옴<br>3) 기저귀 객체 탐지<br> - YOLOV11 커스텀 모델<br>  - 이미지 수집  : 설문조사 및 인터넷 크롤링, 직접 촬영을 통해  다양한 상태의 아기 기저귀 변 이미지 97개 수집함<br>  - 이미지 전처리 : 정확한 판단을 위해 AutoWhiteBalancing 으로 흰 부분의 흰색으로 보이도록 색보정<br>  - 이미지 라벨링 : Roboflow 를 사용하여 기저귀 bounding box 지정 및 라벨링<br>  - 기저귀에 대한 단일 라벨 지정<br>  - 이미지 증강 :  랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강  - 233개<br>4) 결과 출력 및 시각화<br><br>**아기 변 분석 및 챗봇 모듈**<br>1) OPEN AI API 요청<br>  - 프롬프팅 : [아기 기저귀 사진의 똥 부분만 보고 건강 상태를 설명해줘. 이상이 있다면 가능한 원인과 추가로 확인해야 할 사항에 대해 알려줘. 똥이 없는 경우는 000 이라고만 해]<br>  - 변 이미지와 프롬프트를 OPEN AI ChatGPT-4o 모델에 입력으로 전달<br>  - 식별 가능한 아기 변이 있는 기저귀 이미지라면 건강 분석 결과를, 아니라면 촬영 재요청을 위한 “000” 반환<br>  - 챗봇 사용 시 이전 대화 기록이 필요하므로 conversation_history 리스트에 입력 및 답변 순차적으로 저장<br>2) 챗봇<br>  - 음성 인식을 통해 사용자로부터 추가 질문 입력 받음 →  종료시까지 추가질문 프로세스 반복<br>  - 메시지 처리  - conversation_history 와 입력 받은 추가질문을 ChatGPT-4o 모델에 입력으로 전달<br>  - 답변을 사용자에게 전달하고 converstation_history에 추가질문과 답변 저장<br><br>**임신테스트기 분류 모듈**<br>1) 객체 감지 및 이미지 처리<br>  - Google ML Kit를 이용한 이미지 스트림을 통해 실시간으로 감지된 객체를 처리<br>2) 모델 로딩<br >- Roboflow로 학습시킨 모델을 API를 통해 가져옴<br>3) 임신테스트기 이미지 분류<br>  - Roboflow 를 활용한 OPEN AI ChatGPT-4o fine-tuning 커스텀 모델<br>  - 이미지 수집 : 인터넷 크롤링을 통해 임신/비임신 테스트기 결과 이미지 62개 수집함<br>  - 이미지 라벨링 : Roboflow 를 사용하여 결과 부분 bounding box 지정 및 라벨링<br>  - 임신/비임신 2개의 라벨 - 0,1<br>  - 이미지 증강 : 랜덤하게 다양한 옵션을 적용하여 이미지 약 3배 증강 - 150개<br>  - 모델 훈련 : 코로나19 테스트기 이미지 추가 활용 예정 |
| (3) 주요 엔진 및 기능 설계 | **1) 객체탐지 및 촬영 모듈**<br>- Google ML Kit와 Custom YOLOv5 모델로 훈련된 TFlite 파일을 활용하여 이미지 내에서 기저귀를 감지하고, 필요한 영역만 추출한다. <br> **2) 아기 변 분석 모듈** <br> - 1에서 추출된 이미지를 ChatGPT 모델과 연동된 아기 변 분석 모듈이 분석한다. <br> **3) 챗봇 모듈**<br>- OpenAI의 ChatGPT API를 사용하여 변 상태 분석 결과와 연동하여 사용자 질문에 대한 답변을 생성한다. 이때 병원 방문을 권유하는 문장도 필요에 따라 답변에 포함된다. |
| (4) 주요 기능의 구현 | 사용자가 객체탐지 및 촬영 모듈을 통해 이미지를 촬영하면 기저귀와 변을 인식하여 변 상태 분석 모듈로 전달하고, 변 상태 분석 모듈은 이를 분석하여 변의 상태를 설명한다. 아기 변 상태에 대한 설명은 다시 챗봇 모듈로 전달되어 현재 상태와 관련된 추가 질문에 답변한다. 이후 사용자가 음성으로 추가 질문을 하면 STT로 질문 텍스트를 챗봇으로 보내고, 답변을 TTS로 전달하여 사용자가 답변 내용을 음성으로 들을 수 있다. |
| (5) 기타 | |


<br>

# Evaluation
| 항목 | 내용 |
|:---  |---  |
| (1) 평가항목 | **1. 평가항목 선정** <br> 평가항목은 다음과 같다. <br> ① 객체 탐지 카메라의 기저귀 탐지 성능(이하 객체 탐지 카메라)<br> ② 변 분석 모델의 분석 능력(이하 변 분석 모델)<br> ③ 임신 테스트기 분류 모델의 분류 성능(이하 임신 테스트기 분류 모델) <br><br> **2. 선정 사유** <br> ① 객체 탐지 카메라: 본 서비스는 시각장애인 양육자의 사용성을 극대화하는 것을 목표로 하므로, 기저귀 상태를 실시간으로 탐지하는 카메라의 속도와 성능은 사용성의 핵심 평가 요소이다. <br> ② 변 분석 모델: 아기의 변 상태는 건강의 주요 지표이다. 양육자는 해당 모델을 통해 충분히 이상 징후를 감지할 수 있어야 하며, 반복된 분석에서도 일관된 결과를 제공하여 정확도와 신뢰성을 확보해야 한다. <br> ③ 임신 테스트기 분류 모델: 임신 여부는 개인과 가정에 매우 중요한 결정적 요소이며, 시각장애인은 테스트기의 시각적 결과를 확인하기 어려우므로, 분류 모델은 정확한 결과 전달을 보장해야 한다. |
| (2) 평가기준 | **1. 평가 내용** <br> ① 객체 탐지 카메라: 정확도, 재현율, map50-95, 초기화 시간, 객체 탐지 처리 시간 <br> ② 변 분석 모델: 모델이 주는 답변의 구체성, 정확성 <br>  ③ 임신 테스트기 분류 모델: 정확도 <br><br> **2. 평가 기준** <br> ① 객체 탐지 카메라 <br> - 정확도: 탐지된 객체 중 올바르게 탐지된 비율 <br> - 재현율: 실제 객체 중 탐지된 비율 <br> - map50-95: 다양한 IoU 조건에서의 평균 정확도 <br> - 카메라 초기화 시간: 카메라가 실행되기까지 걸리는 시간 <br> - 객체 탐지 처리 시간: 객체를 탐지하고 결과를 반환하는 데 걸리는 시간 <br> ② 변 분석 모델 <br> - 구체성: 분석 결과를 얼마나 세부적이고 명확한지 평가 <br> - 정확성: 모델의 분석 결과가 실제 건강 상태와 얼마나 일치 평가 <br> ③ 임신 테스트기 분류 모델 <br> - 정확도: 모델이 올바르게 결과를 분류한 비율 <br> |
| (3) 평가방식 | **① 객체 탐지 카메라** <br> 총 233개의 기저귀 이미지 데이터셋 중 19개의 테스트 데이터셋에 대해 객체 탐지 결과 확인, 카메라 접근·설정·모델 로드에 걸린 시간 반복 측정, 각 프레임을 처리하는 데 걸린 시간 반복 측정의 과정을 통해 평가하였다.<br> - 정확도 및 재현율: 테스트 데이터셋(기저귀 이미지)을 활용하여 모델의 Precision과 Recall을 수식에 따라 계산 <br> - map50-95: 다양한 IoU 값(0.5 ~ 0.95)을 기준으로 모델의 평균 정확도를 측정 <br> - 초기화시간: 기기에서 카메라 실행 시 초기화 시간을 로그로 기록 <br> - 객체 탐지 처리 시간: 객체 탐지 실행 후 결과 반환까지의 평균 처리 시간을 ms 단위로 측정 <br>  <br> **② 변 분석 모델** <br> 대표적으로 알려진 다양한 변 상태(정상변, 설사, 녹색변, 검은변, 혈변) 이미지 5장에 대한 변 분석 모델의 답변을 분석한다. <br>     - 구체성 및 정확성: 관련 연구인 StoolNet 모델과의 성능 비교. 변 색상, 질감, 이상 징후, 건강 상태 설명의 명확성을 아래와 같이 리커트 5점 척도로 평가 <br> 1점 - 분석 결과가 부정확하고 원인이나 대처 방법이 명시되지 않음. <br> 2점 - 부분적으로 정확하지만 원인과 대처 방법이 불충분하며 설명이 다소 모호함. <br> 3점 - 분석 결과는 대체로 정확하지만 일부 원인과 대처 방법에 대한 설명이 부족함. 기본적인 분석만 제공함. <br> 4점 - 대부분의 변 상태를 정확히 분석하고 원인과 대처 방법을 제시함. 명확하게 설명하나 상담 권유는 부족할 수 있음. <br> 5점 - 변 상태를 정확하고 구체적으로 분석하며 적절한 원인과 대처 방법을 명확히 설명. 전문의 상담 권유까지 제공함. <br><br> **③ 임신 테스트기 분류 모델** <br> - 정확도: 총 201개의 임신테스트기 이미지 데이터셋 중 5장의 테스트 데이터셋에 대해 임신테스트기 분류 결과를 확인한다. 출력한 결과와 정답 라벨을 비교해 정확도를 계산|
| (4) 평가내용 | <img width="723" alt="스크린샷 2024-12-17 오후 5 36 34" src="https://github.com/user-attachments/assets/e34207f6-f579-46fd-9826-99e5851e373f" /> <br> ① 실시간 객체 탐지 카메라 - 정확도: 99.4%, 재현율:94.7%, map50:99.3%, map50-95:86.1%으로 상당히 높은 기저귀 탐지 성능을 보인다. 반응 시간 관련해서는 카메라 초기화에는 평균 1121ms가 소요되며, 이는 앱 실행 시 즉시 사용할 수 있을 만큼 최적화된 속도이다. 객체 탐지 프레임 처리 시간은 평균 15ms이며, 간헐적으로 발생하는 프레임 지연 역시 50ms 내외로 처리된다. <br> ② 변 분석 모델 - 구체성: 모든 테스트셋을 반복시행한 결과 평균 4.89점으로 제시된 모든 변 상태에 대해 적절한 원인과 대처 방법을 정확히 설명하였으며, 프롬프팅 요구사항에 맞게 전문의와의 상담을 권유하는 등 만족스러운 분석 성능을 보였다. <br> ③ 임신 테스트기 분류 모델 - 정확도: 65.4%, 데이터 부족으로 인해 충분한 성능을 내지 못했지만 코로나 테스트기 이미지를 추가 활용하면서 정확도를 46.8%에서 약 20%p 향상시켰다.| 
<br>

# Conclusion
| 항목 | 내용 |
|:---  |---  |
| (1) 결론 | **<과제의 전체 내용>** <br> 그로쓰 17팀 포카리는 시각장애인이 양육을 시작할 때 부딪히는 문제들을 기술적으로 해결하는 데 집중했다. 그 결과 시각장애인 양육자 대상, YOLO와 Multimodal LLM을 활용한, 아기변 분류 기반, 건강 상태 모니터링 서비스를 제안하였을 뿐만 아니라, 임신 테스트기 결과와 아기 변의 상태를 비장애인의 보조 없이 스스로 확인할 수 있는 서비스를 만들었다. <br> **<프로젝트의 중점 Idea 및 기술 구현 내용>** <br> 사용자는 음성 지원이 되는 실시간 객체 탐지 카메라를 통해 사진을 촬영할 수 있으며, 생성형 AI를 활용한 변 분석 모델 및 임신 테스트기 분류 모델을 기반으로 평가 항목과 같이 높은 정확도의 답변을 받아볼 수 있다. 추가적으로 확인하고 싶은 내용이 있는 경우 ChatGPT 기반 챗봇에게 음성으로 질문하고, 음성으로 답변을 받아볼 수 있다. <br> 1. 실시간 객체 탐지 카메라: YOLO 모델을 활용하여 기저귀 상태를 감지한다. 음성 지원 기능을 통해 사용자가 사진을 촬영하고 결과를 확인할 수 있다. <br> 2. 변 분석 결과 확인: 변의 색상, 질감 등을 분석해 건강 상태를 판단하고 원인 및 대처 방법을 제시한다. 필요한 경우 전문의와의 상담을 권유한다. <br> 3. 임신 테스트기 결과 확인: 다양한 브랜드 및 종류의 임신 테스트기 결과를 정확히 분류한다. <br> 4. ChatGPT 기반 챗봇: STT, TTS로 사용자 접근성을 최대화 <br> **<과제의 결과 및 의의>** <br> 스마트푸푸는 시각장애인 양육자의 양육장벽과 복지 사각지대를 해소할 것으로 기대된다. 더 나아가 다량의 고품질 의료 데이터를 확보할 수 있다면 YOLO를 활용한 객체 탐지 모델 및 생성형AI를 활용한 임신 테스트기 분류 모델에 대해 더 견고한 성능을 보일 수 있음을 증명하였다는 의의를 가진다. 추후 시각장애인 양육자 뿐만 아니라 초보 양육자들에게도 서비스를 확장할 수 있을 것으로 기대하고 있다. 초기 구상안이었던 육아 다이어리 형식으로의 전환도 계획하고 있다.|
